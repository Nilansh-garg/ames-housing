import pandas as pd
from sklearn.model_selection import train_test_split,StratifiedShuffleSplit
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder


df = pd.read_csv('data/AmesHousing.csv')


drop_columns = ['Alley','Pool QC','Pool Area','Misc Feature','Misc Val','Fence','Screen Porch','3Ssn Porch','Enclosed Porch','SalePrice']
drop_columns1 = ['Alley','Pool QC','Pool Area','Misc Feature','Misc Val','Fence','SalePrice']


df_train = df.drop(columns = drop_columns).copy()
df_train_1 = df.drop(columns = drop_columns1)
target = df['SalePrice']


num_features = df_train.select_dtypes(exclude = 'object').columns
cat_features = df_train.select_dtypes(include = 'object').columns


# StandardScaler = StandardScaler()
num_pipeline = Pipeline(
    steps = [
    ("imputing",SimpleImputer(strategy = "mean")),
    ("StandardScaler",StandardScaler())
    ]
)
cat_pipeline = Pipeline(
    steps = [
    ("Imputing",SimpleImputer(strategy = "most_frequent")),
    ("Encoder",OneHotEncoder(handle_unknown = 'ignore'))
    ]
)

full_pipeline = ColumnTransformer(
    [
        ("num",num_pipeline,num_features),
        ("cat",cat_pipeline,cat_features)
    ]
)


preprocessor = full_pipeline.fit_transform(df_train)


split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2,random_state = 42)


for train_index, test_index in split.split(df_train, df_train[''])
