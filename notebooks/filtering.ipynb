{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9981325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. Load your dataset\n",
    "# Replace 'your_data.csv' with the actual file name\n",
    "df = pd.read_csv('data/train_input.csv') \n",
    "\n",
    "# Assuming your price column is named 'SalePrice'\n",
    "TARGET_COLUMN = 'Sale Price' \n",
    "N_FEATURES_TO_SELECT = 10 \n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "# Identify Numerical and Categorical Columns\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# 2. Create Preprocessing Pipelines for Robustness\n",
    "# We must handle missing values and encode categorical data BEFORE feature selection.\n",
    "\n",
    "# Pipeline for Numerical Features: Impute (fill NaN) then Scale\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for Categorical Features: Impute (fill NaN) then One-Hot Encode\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')) # 'handle_unknown' prevents errors on new categories\n",
    "])\n",
    "\n",
    "# Create a Column Transformer to apply pipelines to the correct columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    # Keep any other columns untouched (if any)\n",
    ")\n",
    "\n",
    "# 3. Apply the Preprocessing\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "X_processed = X_processed.toarray()\n",
    "# Get the feature names after one-hot encoding\n",
    "feature_names = (\n",
    "    numerical_features + \n",
    "    list(preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features))\n",
    ")\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_processed_df = pd.DataFrame(X_processed, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b571331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 10 Most Important Features for Price Prediction ---\n",
      "Overall Qual        0.597022\n",
      "Gr Liv Area         0.075489\n",
      "Garage Cars         0.058234\n",
      "Garage Area         0.030621\n",
      "1st Flr SF          0.029067\n",
      "Total Bsmt SF       0.028809\n",
      "Lot Area            0.014023\n",
      "BsmtFin SF 1        0.012783\n",
      "Full Bath           0.009657\n",
      "year_since_remod    0.007524\n",
      "dtype: float64\n",
      "\n",
      "Final List of Top Features:\n",
      "['Overall Qual', 'Gr Liv Area', 'Garage Cars', 'Garage Area', '1st Flr SF', 'Total Bsmt SF', 'Lot Area', 'BsmtFin SF 1', 'Full Bath', 'year_since_remod']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 4. Train a Random Forest Model\n",
    "# A robust ensemble model is ideal for generating feature importance.\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_processed_df, y)\n",
    "\n",
    "# 5. Extract Feature Importances\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Create a Series for clear ranking\n",
    "feature_importance_df = pd.Series(importances, index=X_processed_df.columns)\n",
    "\n",
    "# 6. Select the Top N Features\n",
    "top_features = feature_importance_df.nlargest(N_FEATURES_TO_SELECT)\n",
    "\n",
    "print(f\"--- Top {N_FEATURES_TO_SELECT} Most Important Features for Price Prediction ---\")\n",
    "print(top_features)\n",
    "\n",
    "# Final list of features (un-encoded names may need manual review if they are 'one-hot' parts)\n",
    "final_feature_list = top_features.index.tolist()\n",
    "\n",
    "print(\"\\nFinal List of Top Features:\")\n",
    "print(final_feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b894b86",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df2 = df[final_feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a725f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>Garage Area</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>Full Bath</th>\n",
       "      <th>year_since_remod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>7.098376</td>\n",
       "      <td>2.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>7.098376</td>\n",
       "      <td>1209.0</td>\n",
       "      <td>9900</td>\n",
       "      <td>6.966024</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>7.102499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>7.102499</td>\n",
       "      <td>1214.0</td>\n",
       "      <td>10355</td>\n",
       "      <td>6.545350</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.593045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.593045</td>\n",
       "      <td>270.0</td>\n",
       "      <td>4130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>7.085064</td>\n",
       "      <td>2.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>7.085064</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>13110</td>\n",
       "      <td>6.870053</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>7.064759</td>\n",
       "      <td>2.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>7.064759</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>8076</td>\n",
       "      <td>6.559615</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>6</td>\n",
       "      <td>7.201171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>6.705639</td>\n",
       "      <td>780.0</td>\n",
       "      <td>6430</td>\n",
       "      <td>6.660575</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>8</td>\n",
       "      <td>7.935587</td>\n",
       "      <td>3.0</td>\n",
       "      <td>810.0</td>\n",
       "      <td>7.307202</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>15138</td>\n",
       "      <td>6.536692</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>5</td>\n",
       "      <td>6.740519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>6.740519</td>\n",
       "      <td>845.0</td>\n",
       "      <td>6600</td>\n",
       "      <td>6.459904</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>5</td>\n",
       "      <td>7.117206</td>\n",
       "      <td>2.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>7.117206</td>\n",
       "      <td>1232.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6.549651</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>8</td>\n",
       "      <td>7.357556</td>\n",
       "      <td>3.0</td>\n",
       "      <td>648.0</td>\n",
       "      <td>7.357556</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>3982</td>\n",
       "      <td>7.051856</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2344 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Overall Qual  Gr Liv Area  Garage Cars  Garage Area  1st Flr SF  \\\n",
       "0                5     7.098376          2.0        504.0    7.098376   \n",
       "1                5     7.102499          1.0        318.0    7.102499   \n",
       "2                3     6.593045          0.0          0.0    6.593045   \n",
       "3                5     7.085064          2.0        501.0    7.085064   \n",
       "4                6     7.064759          2.0        402.0    7.064759   \n",
       "...            ...          ...          ...          ...         ...   \n",
       "2339             6     7.201171          1.0        440.0    6.705639   \n",
       "2340             8     7.935587          3.0        810.0    7.307202   \n",
       "2341             5     6.740519          1.0        264.0    6.740519   \n",
       "2342             5     7.117206          2.0        490.0    7.117206   \n",
       "2343             8     7.357556          3.0        648.0    7.357556   \n",
       "\n",
       "      Total Bsmt SF  Lot Area  BsmtFin SF 1  Full Bath  year_since_remod  \n",
       "0            1209.0      9900      6.966024          1                44  \n",
       "1            1214.0     10355      6.545350          2                40  \n",
       "2             270.0      4130      0.000000          1                 5  \n",
       "3            1153.0     13110      6.870053          2                34  \n",
       "4            1160.0      8076      6.559615          2                12  \n",
       "...             ...       ...           ...        ...               ...  \n",
       "2339          780.0      6430      6.660575          1                56  \n",
       "2340         1462.0     15138      6.536692          2                13  \n",
       "2341          845.0      6600      6.459904          1                 3  \n",
       "2342         1232.0      9600      6.549651          1                44  \n",
       "2343         1520.0      3982      7.051856          2                 0  \n",
       "\n",
       "[2344 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9640704",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Assuming feature_names is the list of column names after OHE\n",
    "# Assuming importances is the model.feature_importances_ array\n",
    "\n",
    "grouped_importance = {}\n",
    "\n",
    "for feature_name, score in feature_importance_df.items():\n",
    "    # Example: Group all columns that start with 'Category_'\n",
    "    if feature_name.startswith('Category_'):\n",
    "        group_key = 'Original_Category'\n",
    "        grouped_importance[group_key] = grouped_importance.get(group_key, 0) + score\n",
    "    else:\n",
    "        # Keep non-OHE (numeric) features as they are\n",
    "        grouped_importance[feature_name] = score\n",
    "\n",
    "# The value for 'Original_Category' is its total importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52576eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_processed_df = X_processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8ff7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_processed_df['Sale Price'] = df['Sale Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50b2d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Grouped Feature Names (Keys) ---\n",
      "dict_keys(['Order', 'PID', 'MS SubClass', 'Lot Frontage', 'Lot Area', 'Overall Qual', 'Overall Cond', 'Year Built', 'Year Remod/Add', 'Mas Vnr Area', 'BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF', 'Total Bsmt SF', '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr', 'TotRms AbvGrd', 'Fireplaces', 'Garage Yr Blt', 'Garage Cars', 'Garage Area', 'Wood Deck SF', 'Open Porch SF', 'Mo Sold', 'Yr Sold', 'Age', 'year', 'MS Zoning', 'Street', 'Lot Shape', 'Land Contour', 'Utilities', 'Lot Config', 'Land Slope', 'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', 'Roof Style', 'Roof Matl', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Exter Qual', 'Exter Cond', 'Foundation', 'Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin Type 2', 'Heating', 'Heating QC', 'Central Air', 'Electrical', 'Kitchen Qual', 'Functional', 'Fireplace Qu', 'Garage Type', 'Garage Finish', 'Garage Qual', 'Garage Cond', 'Paved Drive', 'Sale Type', 'Sale Condition'])\n",
      "\n",
      "--- Example Group (MS Zoning) ---\n",
      "['MS Zoning_A (agr)', 'MS Zoning_C (all)', 'MS Zoning_FV', 'MS Zoning_I (all)', 'MS Zoning_RH', 'MS Zoning_RL', 'MS Zoning_RM']\n"
     ]
    }
   ],
   "source": [
    "all_columns = ['Order', 'PID', 'MS SubClass', 'Lot Frontage', 'Lot Area', 'Overall Qual', 'Overall Cond', 'Year Built', 'Year Remod/Add', 'Mas Vnr Area', 'BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF', 'Total Bsmt SF', '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr', 'TotRms AbvGrd', 'Fireplaces', 'Garage Yr Blt', 'Garage Cars', 'Garage Area', 'Wood Deck SF', 'Open Porch SF', 'Mo Sold', 'Yr Sold', 'Age', 'year_since_remod', 'MS Zoning_A (agr)', 'MS Zoning_C (all)', 'MS Zoning_FV', 'MS Zoning_I (all)', 'MS Zoning_RH', 'MS Zoning_RL', 'MS Zoning_RM', 'Street_Grvl', 'Street_Pave', 'Lot Shape_IR1', 'Lot Shape_IR2', 'Lot Shape_IR3', 'Lot Shape_Reg', 'Land Contour_Bnk', 'Land Contour_HLS', 'Land Contour_Low', 'Land Contour_Lvl', 'Utilities_AllPub', 'Utilities_NoSeWa', 'Utilities_NoSewr', 'Lot Config_Corner', 'Lot Config_CulDSac', 'Lot Config_FR2', 'Lot Config_FR3', 'Lot Config_Inside', 'Land Slope_Gtl', 'Land Slope_Mod', 'Land Slope_Sev', 'Neighborhood_Blmngtn', 'Neighborhood_Blueste', 'Neighborhood_BrDale', 'Neighborhood_BrkSide', 'Neighborhood_ClearCr', 'Neighborhood_CollgCr', 'Neighborhood_Crawfor', 'Neighborhood_Edwards', 'Neighborhood_Gilbert', 'Neighborhood_Greens', 'Neighborhood_GrnHill', 'Neighborhood_IDOTRR', 'Neighborhood_MeadowV', 'Neighborhood_Mitchel', 'Neighborhood_NAmes', 'Neighborhood_NPkVill', 'Neighborhood_NWAmes', 'Neighborhood_NoRidge', 'Neighborhood_NridgHt', 'Neighborhood_OldTown', 'Neighborhood_SWISU', 'Neighborhood_Sawyer', 'Neighborhood_SawyerW', 'Neighborhood_Somerst', 'Neighborhood_StoneBr', 'Neighborhood_Timber', 'Neighborhood_Veenker', 'Condition 1_Artery', 'Condition 1_Feedr', 'Condition 1_Norm', 'Condition 1_PosA', 'Condition 1_PosN', 'Condition 1_RRAe', 'Condition 1_RRAn', 'Condition 1_RRNe', 'Condition 1_RRNn', 'Condition 2_Artery', 'Condition 2_Feedr', 'Condition 2_Norm', 'Condition 2_PosA', 'Condition 2_PosN', 'Condition 2_RRNn', 'Bldg Type_1Fam', 'Bldg Type_2fmCon', 'Bldg Type_Duplex', 'Bldg Type_Twnhs', 'Bldg Type_TwnhsE', 'House Style_1.5Fin', 'House Style_1.5Unf', 'House Style_1Story', 'House Style_2.5Fin', 'House Style_2.5Unf', 'House Style_2Story', 'House Style_SFoyer', 'House Style_SLvl', 'Roof Style_Flat', 'Roof Style_Gable', 'Roof Style_Gambrel', 'Roof Style_Hip', 'Roof Style_Mansard', 'Roof Style_Shed', 'Roof Matl_ClyTile', 'Roof Matl_CompShg', 'Roof Matl_Membran', 'Roof Matl_Metal', 'Roof Matl_Roll', 'Roof Matl_Tar&Grv', 'Roof Matl_WdShake', 'Roof Matl_WdShngl', 'Exterior 1st_AsbShng', 'Exterior 1st_AsphShn', 'Exterior 1st_BrkComm', 'Exterior 1st_BrkFace', 'Exterior 1st_CBlock', 'Exterior 1st_CemntBd', 'Exterior 1st_HdBoard', 'Exterior 1st_MetalSd', 'Exterior 1st_Plywood', 'Exterior 1st_PreCast', 'Exterior 1st_Stone', 'Exterior 1st_Stucco', 'Exterior 1st_VinylSd', 'Exterior 1st_Wd Sdng', 'Exterior 1st_WdShing', 'Exterior 2nd_AsbShng', 'Exterior 2nd_AsphShn', 'Exterior 2nd_Brk Cmn', 'Exterior 2nd_BrkFace', 'Exterior 2nd_CBlock', 'Exterior 2nd_CmentBd', 'Exterior 2nd_HdBoard', 'Exterior 2nd_ImStucc', 'Exterior 2nd_MetalSd', 'Exterior 2nd_Other', 'Exterior 2nd_Plywood', 'Exterior 2nd_PreCast', 'Exterior 2nd_Stone', 'Exterior 2nd_Stucco', 'Exterior 2nd_VinylSd', 'Exterior 2nd_Wd Sdng', 'Exterior 2nd_Wd Shng', 'Mas Vnr Type_BrkCmn', 'Mas Vnr Type_BrkFace', 'Mas Vnr Type_CBlock', 'Mas Vnr Type_Stone', 'Exter Qual_Ex', 'Exter Qual_Fa', 'Exter Qual_Gd', 'Exter Qual_TA', 'Exter Cond_Ex', 'Exter Cond_Fa', 'Exter Cond_Gd', 'Exter Cond_Po', 'Exter Cond_TA', 'Foundation_BrkTil', 'Foundation_CBlock', 'Foundation_PConc', 'Foundation_Slab', 'Foundation_Stone', 'Foundation_Wood', 'Bsmt Qual_Ex', 'Bsmt Qual_Fa', 'Bsmt Qual_Gd', 'Bsmt Qual_Po', 'Bsmt Qual_TA', 'Bsmt Cond_Ex', 'Bsmt Cond_Fa', 'Bsmt Cond_Gd', 'Bsmt Cond_Po', 'Bsmt Cond_TA', 'Bsmt Exposure_Av', 'Bsmt Exposure_Gd', 'Bsmt Exposure_Mn', 'Bsmt Exposure_No', 'BsmtFin Type 1_ALQ', 'BsmtFin Type 1_BLQ', 'BsmtFin Type 1_GLQ', 'BsmtFin Type 1_LwQ', 'BsmtFin Type 1_Rec', 'BsmtFin Type 1_Unf', 'BsmtFin Type 2_ALQ', 'BsmtFin Type 2_BLQ', 'BsmtFin Type 2_GLQ', 'BsmtFin Type 2_LwQ', 'BsmtFin Type 2_Rec', 'BsmtFin Type 2_Unf', 'Heating_Floor', 'Heating_GasA', 'Heating_GasW', 'Heating_Grav', 'Heating_OthW', 'Heating_Wall', 'Heating QC_Ex', 'Heating QC_Fa', 'Heating QC_Gd', 'Heating QC_Po', 'Heating QC_TA', 'Central Air_N', 'Central Air_Y', 'Electrical_FuseA', 'Electrical_FuseF', 'Electrical_FuseP', 'Electrical_Mix', 'Electrical_SBrkr', 'Kitchen Qual_Ex', 'Kitchen Qual_Fa', 'Kitchen Qual_Gd', 'Kitchen Qual_TA', 'Functional_Maj1', 'Functional_Maj2', 'Functional_Min1', 'Functional_Min2', 'Functional_Mod', 'Functional_Sal', 'Functional_Sev', 'Functional_Typ', 'Fireplace Qu_Ex', 'Fireplace Qu_Fa', 'Fireplace Qu_Gd', 'Fireplace Qu_Po', 'Fireplace Qu_TA', 'Garage Type_2Types', 'Garage Type_Attchd', 'Garage Type_Basment', 'Garage Type_BuiltIn', 'Garage Type_CarPort', 'Garage Type_Detchd', 'Garage Finish_Fin', 'Garage Finish_RFn', 'Garage Finish_Unf', 'Garage Qual_Ex', 'Garage Qual_Fa', 'Garage Qual_Gd', 'Garage Qual_Po', 'Garage Qual_TA', 'Garage Cond_Ex', 'Garage Cond_Fa', 'Garage Cond_Gd', 'Garage Cond_Po', 'Garage Cond_TA', 'Paved Drive_N', 'Paved Drive_P', 'Paved Drive_Y', 'Sale Type_COD', 'Sale Type_CWD', 'Sale Type_Con', 'Sale Type_ConLD', 'Sale Type_ConLI', 'Sale Type_ConLw', 'Sale Type_New', 'Sale Type_Oth', 'Sale Type_VWD', 'Sale Type_WD ', 'Sale Condition_Abnorml', 'Sale Condition_AdjLand', 'Sale Condition_Alloca', 'Sale Condition_Family', 'Sale Condition_Normal', 'Sale Condition_Partial']\n",
    "\n",
    "\n",
    "feature_groups = {}\n",
    "numeric_features = []\n",
    "\n",
    "for col in all_columns:\n",
    "    if '_' in col:\n",
    "        # It's an OHE column. Group it by the original feature name (before the first underscore).\n",
    "        original_feature = col.split('_')[0]\n",
    "        \n",
    "        # NOTE: Some features have underscores in their values (e.g., 'Roof Matl_Tar&Grv' or 'Sale Type_WD ').\n",
    "        # We need to ensure we capture the full original name, not just the part before the first underscore.\n",
    "        # A more robust approach for this specific dataset: \n",
    "        # Find the first capital letter that follows a space, or simply rely on the first segment.\n",
    "        \n",
    "        # Simple split on the first underscore (usually works for Ames Housing dataset)\n",
    "        original_feature = col.split('_', 1)[0]\n",
    "        \n",
    "        # Handle cases where the original name has an underscore (like 'BsmtFin Type 1')\n",
    "        # We'll rely on the simple split for this code to stay clean, assuming standard OHE practices.\n",
    "\n",
    "        if original_feature not in feature_groups:\n",
    "            feature_groups[original_feature] = []\n",
    "        feature_groups[original_feature].append(col)\n",
    "    else:\n",
    "        # It's a numeric/ordinal feature. Treat it as its own group.\n",
    "        # Add it to the dictionary where the key is the feature name and the value is a list containing itself.\n",
    "        feature_groups[col] = [col]\n",
    "\n",
    "\n",
    "# Optional: Verify the grouping by printing the dictionary keys (the feature names)\n",
    "print(\"--- Grouped Feature Names (Keys) ---\")\n",
    "print(feature_groups.keys())\n",
    "\n",
    "print(\"\\n--- Example Group (MS Zoning) ---\")\n",
    "print(feature_groups.get('MS Zoning'))\n",
    "\n",
    "# Now, use this 'feature_groups' dictionary in the PermutationImportance step!\n",
    "# perm_imp = PermutationImportance(model, ..., feature_names=feature_groups).fit(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca8d2de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R^2 on test set: 0.8750\n",
      "\n",
      "--- Grouped Permutation Feature Importance ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names has a wrong length: expected=282, got=74",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 82\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Grouped Permutation Feature Importance ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Use eli5.show_weights to display the grouped results clearly\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# The 'weight' shows the total drop in model performance (R2 score in this case) \u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# when the feature group is shuffled.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Display the report using the feature_groups dictionary\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m html_report \u001b[38;5;241m=\u001b[39m eli5\u001b[38;5;241m.\u001b[39mshow_weights(\n\u001b[0;32m     83\u001b[0m     perm_imp, \n\u001b[0;32m     84\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_groups,\n\u001b[0;32m     85\u001b[0m     target_names\u001b[38;5;241m=\u001b[39m[target_col] \u001b[38;5;66;03m# Optional: specify the target name\u001b[39;00m\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     88\u001b[0m display(html_report)\n",
      "File \u001b[1;32mc:\\Users\\MY LENOVO\\anaconda3\\Lib\\site-packages\\eli5\\ipython.py:130\u001b[0m, in \u001b[0;36mshow_weights\u001b[1;34m(estimator, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Return an explanation of estimator parameters (weights)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03mas an IPython.display.HTML object. Use this function\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03mto show classifier weights in IPython.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m format_kwargs, explain_kwargs \u001b[38;5;241m=\u001b[39m _split_kwargs(kwargs)\n\u001b[1;32m--> 130\u001b[0m expl \u001b[38;5;241m=\u001b[39m explain_weights(estimator, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexplain_kwargs)\n\u001b[0;32m    131\u001b[0m _set_html_kwargs_defaults(format_kwargs)\n\u001b[0;32m    132\u001b[0m html \u001b[38;5;241m=\u001b[39m format_as_html(expl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\MY LENOVO\\anaconda3\\Lib\\functools.py:934\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    932\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    933\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dispatch(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\MY LENOVO\\anaconda3\\Lib\\site-packages\\eli5\\sklearn\\explain_weights.py:505\u001b[0m, in \u001b[0;36mexplain_permutation_importance\u001b[1;34m(estimator, vec, top, target_names, targets, feature_names, feature_re, feature_filter)\u001b[0m\n\u001b[0;32m    503\u001b[0m coef \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m    504\u001b[0m coef_std \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mfeature_importances_std_\n\u001b[1;32m--> 505\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_feature_importance_explanation(estimator, vec, coef,\n\u001b[0;32m    506\u001b[0m     coef_std\u001b[38;5;241m=\u001b[39mcoef_std,\n\u001b[0;32m    507\u001b[0m     feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[0;32m    508\u001b[0m     feature_filter\u001b[38;5;241m=\u001b[39mfeature_filter,\n\u001b[0;32m    509\u001b[0m     feature_re\u001b[38;5;241m=\u001b[39mfeature_re,\n\u001b[0;32m    510\u001b[0m     top\u001b[38;5;241m=\u001b[39mtop,\n\u001b[0;32m    511\u001b[0m     description\u001b[38;5;241m=\u001b[39mDESCRIPTION_SCORE_DECREASE \u001b[38;5;241m+\u001b[39m estimator\u001b[38;5;241m.\u001b[39mcaveats_,\n\u001b[0;32m    512\u001b[0m     is_regression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28misinstance\u001b[39m(estimator\u001b[38;5;241m.\u001b[39mwrapped_estimator_, RegressorMixin),\n\u001b[0;32m    513\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\MY LENOVO\\anaconda3\\Lib\\site-packages\\eli5\\_feature_importances.py:31\u001b[0m, in \u001b[0;36mget_feature_importance_explanation\u001b[1;34m(estimator, vec, coef, feature_names, feature_filter, feature_re, top, description, is_regression, estimator_feature_names, num_features, coef_std)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_feature_importance_explanation\u001b[39m(estimator, vec, coef, feature_names,\n\u001b[0;32m     25\u001b[0m                                        feature_filter, feature_re, top,\n\u001b[0;32m     26\u001b[0m                                        description, is_regression,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m                                        coef_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# type: (...) -> Explanation\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     feature_names, flt_indices \u001b[38;5;241m=\u001b[39m get_feature_names_filtered(\n\u001b[0;32m     32\u001b[0m         estimator, vec,\n\u001b[0;32m     33\u001b[0m         feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[0;32m     34\u001b[0m         estimator_feature_names\u001b[38;5;241m=\u001b[39mestimator_feature_names,\n\u001b[0;32m     35\u001b[0m         feature_filter\u001b[38;5;241m=\u001b[39mfeature_filter,\n\u001b[0;32m     36\u001b[0m         feature_re\u001b[38;5;241m=\u001b[39mfeature_re,\n\u001b[0;32m     37\u001b[0m         num_features\u001b[38;5;241m=\u001b[39mnum_features,\n\u001b[0;32m     38\u001b[0m     )\n\u001b[0;32m     39\u001b[0m     feature_importances \u001b[38;5;241m=\u001b[39m get_feature_importances_filtered(\n\u001b[0;32m     40\u001b[0m         coef, feature_names, flt_indices, top, coef_std)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Explanation(\n\u001b[0;32m     42\u001b[0m         feature_importances\u001b[38;5;241m=\u001b[39mfeature_importances,\n\u001b[0;32m     43\u001b[0m         description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m         is_regression\u001b[38;5;241m=\u001b[39mis_regression,\n\u001b[0;32m     47\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MY LENOVO\\anaconda3\\Lib\\site-packages\\eli5\\sklearn\\utils.py:133\u001b[0m, in \u001b[0;36mget_feature_names_filtered\u001b[1;34m(clf, vec, bias_name, feature_names, num_features, feature_filter, feature_re, estimator_feature_names)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_feature_names_filtered\u001b[39m(\n\u001b[0;32m    129\u001b[0m         clf, vec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, bias_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<BIAS>\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    130\u001b[0m         feature_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    131\u001b[0m         feature_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feature_re\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    132\u001b[0m         estimator_feature_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[FeatureNames, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m--> 133\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m get_feature_names(\n\u001b[0;32m    134\u001b[0m         clf\u001b[38;5;241m=\u001b[39mclf,\n\u001b[0;32m    135\u001b[0m         vec\u001b[38;5;241m=\u001b[39mvec,\n\u001b[0;32m    136\u001b[0m         bias_name\u001b[38;5;241m=\u001b[39mbias_name,\n\u001b[0;32m    137\u001b[0m         feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[0;32m    138\u001b[0m         num_features\u001b[38;5;241m=\u001b[39mnum_features,\n\u001b[0;32m    139\u001b[0m         estimator_feature_names\u001b[38;5;241m=\u001b[39mestimator_feature_names,\n\u001b[0;32m    140\u001b[0m     )\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_names\u001b[38;5;241m.\u001b[39mhandle_filter(feature_filter, feature_re)\n",
      "File \u001b[1;32mc:\\Users\\MY LENOVO\\anaconda3\\Lib\\site-packages\\eli5\\sklearn\\utils.py:122\u001b[0m, in \u001b[0;36mget_feature_names\u001b[1;34m(clf, vec, bias_name, feature_names, num_features, estimator_feature_names)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(feature_names) \u001b[38;5;241m!=\u001b[39m num_features:\n\u001b[1;32m--> 122\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names has a wrong length: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, got=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (num_features,\n\u001b[0;32m    124\u001b[0m                                                   \u001b[38;5;28mlen\u001b[39m(feature_names)))\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FeatureNames(feature_names, bias_name\u001b[38;5;241m=\u001b[39mbias_name)\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names has a wrong length: expected=282, got=74"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import eli5\n",
    "from IPython.display import display # For displaying the results in a notebook\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# ASSUMPTION: Replace this with your actual DataFrame loading and cleaning\n",
    "# ----------------------------------------------------------------------\n",
    "# Since you didn't provide the DataFrame, we'll create a synthetic one \n",
    "# using a small subset of your features for the code to be runnable.\n",
    "\n",
    "# Sample features from your list\n",
    "sample_features = ['Lot Area', 'Overall Qual', 'MS Zoning_RL', 'MS Zoning_RM', \n",
    "                   'Neighborhood_CollgCr', 'Neighborhood_OldTown']\n",
    "target_col = 'Sale Price'\n",
    "num_rows = 500\n",
    "\n",
    "# Create a synthetic DataFrame (REPLACE THIS WITH YOUR ACTUAL DF)\n",
    "\n",
    "df = x1_processed_df\n",
    "\n",
    "# Ensure the columns in X match your full list of columns exactly for real data\n",
    "X = df.drop(target_col, axis=1) \n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Feature Grouping (Using the same logic as the previous response)\n",
    "#    This step must be run on the actual columns of X_train/X_test\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "feature_groups = {}\n",
    "all_columns = X.columns.tolist()\n",
    "\n",
    "for col in all_columns:\n",
    "    if '_' in col:\n",
    "        # Group by the original feature name (before the first underscore)\n",
    "        # Using maxsplit=1 to handle names with underscores in the category value\n",
    "        original_feature = col.split('_', 1)[0]\n",
    "        \n",
    "        # NOTE: If your original feature name had spaces (e.g., 'MS Zoning'), \n",
    "        # this will correctly group all 'MS Zoning_' columns.\n",
    "\n",
    "        if original_feature not in feature_groups:\n",
    "            feature_groups[original_feature] = []\n",
    "        feature_groups[original_feature].append(col)\n",
    "    else:\n",
    "        # Numeric/Ordinal features are groups of one\n",
    "        feature_groups[col] = [col]\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Train Model and Calculate Grouped Permutation Importance\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Initialize and train a robust model (Random Forest is common for importance)\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Model R^2 on test set: {model.score(X_test, y_test):.4f}\\n\")\n",
    "\n",
    "# Initialize Permutation Importance object with the feature_groups\n",
    "perm_imp = PermutationImportance(\n",
    "    model, \n",
    "    random_state=42, \n",
    "    # n_iter=10 is the default. You might increase this for more stable results (e.g., 50)\n",
    ").fit(X_test, y_test)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. Display Results\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "print(\"--- Grouped Permutation Feature Importance ---\")\n",
    "\n",
    "# Use eli5.show_weights to display the grouped results clearly\n",
    "# The 'weight' shows the total drop in model performance (R2 score in this case) \n",
    "# when the feature group is shuffled.\n",
    "\n",
    "# Display the report using the feature_groups dictionary\n",
    "html_report = eli5.show_weights(\n",
    "    perm_imp, \n",
    "    feature_names=feature_groups,\n",
    "    target_names=[target_col] # Optional: specify the target name\n",
    ")\n",
    "\n",
    "display(html_report) # Displays the interactive HTML table in a notebook/VS Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
