import pandas as pd
import numpy as np
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor
from sklearn.linear_model import Lasso, LinearRegression, Ridge
from catboost import CatBoostRegressor
from sklearn.model_selection import RandomizedSearchCV
from xgboost import XGBRegressor
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder


df = pd.read_csv('data/train_input.csv', na_values = ['','NaN','NA'], keep_default_na = False)
df_test_file = pd.read_csv('data/test_input.csv',na_values = ['','NaN','NA'], keep_default_na = False)


target_train = df['Sale Price'].copy()
target_test = df_test_file['Sale Price'].copy()

train_features = df.drop("Sale Price", axis = 1)
test_features = df_test_file.drop("Sale Price", axis = 1)

num_features = train_features.select_dtypes(exclude = 'object').columns.tolist()
cat_features = train_features.select_dtypes(include = 'object').columns.tolist()


# StandardScaler = StandardScaler()
num_pipeline = Pipeline(
    steps = [
    ("imputing",SimpleImputer(strategy = "mean")),
    ]
)
cat_pipeline = Pipeline(
    steps = [
    ("Imputing",SimpleImputer(strategy = "most_frequent")),
    ("Encoder",OneHotEncoder(handle_unknown = 'ignore'))
    ]
)
full_pipeline = ColumnTransformer(
    [
        ("num",num_pipeline,num_features),
        ("cat",cat_pipeline,cat_features)
    ]
)


df_train = full_pipeline.fit_transform(train_features)
df_test = full_pipeline.transform(test_features)


def evaluate_model(true, predicted):
    mae = mean_absolute_error(true,predicted)
    mse = mean_squared_error(true, predicted)
    rmse = np.sqrt(mean_squared_error(true, predicted))
    r2_Score = r2_score(true, predicted)
    return mae, rmse, r2_Score


models = {
    "lasso":Lasso(),
    "Linear Regression": LinearRegression(),
    "KNeighbors Regressor": KNeighborsRegressor(),
    "Ridge":Ridge(),
    "Random Forest":RandomForestRegressor(),
    "Decision Tree":DecisionTreeRegressor(),
    "Ada Boost Regressor":AdaBoostRegressor(),
    "Xgb boost":XGBRegressor()
}


model_list = []
r2_list = []

for i in range(len(models)):
    model = list(models.values())[i]
    model.fit(df_train, target_train)

    y_train_pred = model.predict(df_train)
    y_test_pred = model.predict(df_test)

    model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(target_train, y_train_pred)
    model_test_mae, model_test_rmse, model_test_r2 = evaluate_model(target_test, y_test_pred)

    print(list(models.keys())[i])
    model_list.append(list(models.keys())[i])
    
    print("- Model performance for Training set")
    print("- Root Mean Squared Error:{:.4f}".format(model_train_rmse))
    print("- Mean Absolute Error:{:.4f}".format(model_train_mae))
    print("- R2 Score: {:.4f}".format(model_train_r2))
    
    print('----------------------------------------')
    
    print('- Model performance for Test set')
    print("- Root Mean Squared Error :{:.4f}".format(model_test_rmse))
    print("- Mean Absolute Error:{:.4f}".format(model_test_mae))
    print("- R2 Score: {:.4f}".format(model_test_r2))
    print()
    r2_list.append(model_test_r2)
    





print(best_xgb_model)


# Assuming 'random_search' object from the previous fit is still in memory

# 1. Retrieve the optimal model object
best_xgb_model = random_search.best_estimator_

# 2. Evaluate the model on the unseen test set
# This provides the final, non-cross-validated R2 score for reporting.
test_r2_score = best_xgb_model.score(df_train, target_train)

print(f"Final Tuned Model R2 on Test Set: {test_r2_score}")


import joblib

# Assuming 'best_xgb_model' is the object you retrieved from random_search.best_estimator_

# Define the filename
filename = 'best_xgb_model_tuned.joblib'

# Save the model to file
joblib.dump(best_xgb_model, filename)

print(f"Model successfully saved to {filename}")

# --- To Load the model later ---
# loaded_model = joblib.load(filename)
